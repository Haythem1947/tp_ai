# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, f1_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import label_binarize

# Load the dataset
file_path = "iris_label.xlsx"
df = pd.read_excel(file_path)

# Step 1: Preprocess the data
# Separate features (X) and target (y)
X = df.drop('species', axis=1)  # Features: Sepal and Petal dimensions
y = df['species']  # Target: Species

# Encode the target variable into numeric labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)  # Convert string labels to numeric

# Normalize the feature data
scaler = StandardScaler()
X_normalized = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_encoded, test_size=0.2, random_state=42)

# Visualize the data distribution

plt.figure(figsize=(7, 5))
plt.scatter(X.values[:, 0], X.values[:, 1], c=y_encoded, cmap='viridis')  # Sepal length vs Sepal width
clb = plt.colorbar()
clb.ax.set_yticks([0, 1, 2], labels=label_encoder.classes_)
plt.xlabel('Sepal length (cm)')
plt.ylabel('Sepal width (cm)')
plt.title("Scatter plot of Sepal Length vs Sepal Width")
plt.tight_layout()
plt.show()

# Step 3: Implement GridSearchCV to find the best value of k for KNN
param_grid = {'n_neighbors': np.arange(1, 21)}  # Search for k in the range 1 to 20
grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy', verbose=1)

# Fit the grid search
grid_search.fit(X_train, y_train)

# Get the best value of k
best_k = grid_search.best_params_['n_neighbors']
print(f"Best k found: {best_k}")

# Step 4: Train KNN with the best k found by GridSearchCV

knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(X_train, y_train)  # Train the KNN model on the training data

# Predictions
y_pred = knn.predict(X_test)

# 1. Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

# 2. Classification Report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# 3. Confusion Matrix
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# 4. Cross-Validation
cv_scores = cross_val_score(knn, X_normalized, y_encoded, cv=5)
print(f"\nCross-Validation Scores: {cv_scores}")
print(f"Mean Cross-Validation Score: {cv_scores.mean():.4f}")

# 5. Learning Curve
train_sizes, train_scores, valid_scores = learning_curve(knn,X_normalized, y_encoded,cv=StratifiedKFold(5),n_jobs=-1,train_sizes=np.linspace(0.1, 1.0, 10))                                                      

# Calculate mean and standard deviation for the training and validation scores
train_scores_mean = np.mean(train_scores, axis=1)
valid_scores_mean = np.mean(valid_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
valid_scores_std = np.std(valid_scores, axis=1)

# Plot learning curve
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores_mean, label="Training score", color="blue")
plt.plot(train_sizes, valid_scores_mean, label="Validation score", color="green")
plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="blue")
plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std, valid_scores_mean + valid_scores_std, alpha=0.1, color="green")
plt.title('Learning Curve (KNN)')
plt.xlabel('Training Size')
plt.ylabel('Score')
plt.legend()
plt.grid()
plt.show() 
   
# 6. ROC Curve and AUC
y_bin = label_binarize(y_test, classes=np.unique(y_encoded))
plt.figure(figsize=(10, 6))

colors = ['blue', 'green', 'red']
labels = ['Setosa', 'Versicolor', 'Virginica']

for i in range(3):
    y_score = knn.predict_proba(X_test)[:, i]
    fpr, tpr, _ = roc_curve(y_bin[:, i], y_score)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=colors[i], lw=2,
             label=f'{labels[i]} vs rest (AUC = {roc_auc:.2f})')
    print(f"ROC AUC ({labels[i]} vs rest): {roc_auc:.4f}")
# Plot ROC Curve
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for KNN Classifier')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# 7. Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_bin[:, 0], knn.predict_proba(X_test)[:, 0])
plt.figure(figsize=(10, 6))
plt.plot(recall, precision, color="blue", label="Class 0 Precision-Recall curve")
precision, recall, _ = precision_recall_curve(y_bin[:, 1], knn.predict_proba(X_test)[:, 1])
plt.plot(recall, precision, color="green", label="Class 1 Precision-Recall curve")
precision, recall, _ = precision_recall_curve(y_bin[:, 2], knn.predict_proba(X_test)[:, 2])
plt.plot(recall, precision, color="red", label="Class 2 Precision-Recall curve")
plt.title('Precision-Recall Curve for KNN')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend(loc="lower left")
plt.grid(True)
plt.show()

# 8. F1-Score
f1 = f1_score(y_test, y_pred, average='weighted')
print(f"\nWeighted F1-Score: {f1:.4f}")
